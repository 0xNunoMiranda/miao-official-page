"use client"

import type React from "react"
import { useState, useRef, useEffect } from "react"
import { Send, X, Loader2, Mic, Keyboard, Play, Pause } from "lucide-react"
// Voice input component - uses Mic icon for both states (no MicOff needed)
import TamagotchiCat from "./TamagotchiCat"
import { useLanguage } from "../lib/language-context"
import { useSpeechRecognition } from "../lib/hooks/use-speech-recognition"
import { useSpeechSynthesis } from "../lib/hooks/use-speech-synthesis"
import { VoiceIndicator } from "./VoiceIndicator"

interface Message {
  id: string
  role: "user" | "assistant"
  content: string
  timestamp: number
}

interface VisualNovelChatProps {
  isOpen: boolean
  onClose: () => void
  videoRef?: React.RefObject<HTMLVideoElement | null>
}

export default function VisualNovelChat({ isOpen, onClose, videoRef }: VisualNovelChatProps) {
  const { t, language } = useLanguage()
  const [messages, setMessages] = useState<Message[]>([])
  const [input, setInput] = useState("")
  const [loading, setLoading] = useState(false)
  const [queueProgress, setQueueProgress] = useState<{ queuePosition: number; progress: number } | null>(null)
  const [inputMode, setInputMode] = useState<"text" | "voice">("text")
  const [currentEmotion, setCurrentEmotion] = useState<string>("excited")
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const inputRef = useRef<HTMLInputElement>(null)
  const lastSpokenMessageIdRef = useRef<string | null>(null) // Rastrear √∫ltima mensagem falada
  const [playingMessageId, setPlayingMessageId] = useState<string | null>(null) // Rastrear qual mensagem est√° sendo reproduzida

  // Fun√ß√£o para detectar emo√ß√£o no texto da resposta
  const detectEmotion = (text: string): string => {
    const textLower = text.toLowerCase()
    
    // Palavras-chave para cada emo√ß√£o
    const emotionKeywords: { [key: string]: RegExp[] } = {
      laugh: [
        /haha|hehe|üòÇ|üòÜ|üòÑ|lol|funny|engra√ßado|divertido|riso/g,
        /\b(laugh|chuckle|giggle)\b/g,
      ],
      happy: [
        /üòä|üòÉ|üòÅ|feliz|alegre|happy|joy|great|awesome|incr√≠vel|maravilhoso/g,
        /\b(happy|glad|pleased|delighted|cheerful|joyful)\b/g,
      ],
      surprise: [
        /wow|uau|surpresa|surprise|incr√≠vel|amazing|wonderful/g,
        /üòÆ|üò≤|ü§©|omg|n√£o acredito/g,
      ],
      sad: [
        /üò¢|üò≠|triste|sad|sorry|desculpa|desculpe|unfortunately/g,
        /\b(sad|sorry|unfortunately|regret|sorrowful)\b/g,
      ],
      mad: [
        /üò†|üò°|bravo|angry|mad|raiva|irritado|furioso/g,
        /\b(angry|mad|furious|annoyed|irritated)\b/g,
      ],
      sleepy: [
        /üò¥|sleepy|sono|cansado|tired|sleep|dormir/g,
        /\b(sleepy|tired|exhausted|drowsy)\b/g,
      ],
      excited: [
        /excited|empolgado|emocionado|üòÜ|üéâ|yay/g,
        /\b(excited|thrilled|pumped|enthusiastic)\b/g,
      ],
    }

    // Contar matches para cada emo√ß√£o
    let maxMatches = 0
    let detectedEmotion = "excited" // default

    for (const [emotion, patterns] of Object.entries(emotionKeywords)) {
      let matches = 0
      for (const pattern of patterns) {
        const found = textLower.match(pattern)
        if (found) matches += found.length
      }
      if (matches > maxMatches) {
        maxMatches = matches
        detectedEmotion = emotion
      }
    }

    return detectedEmotion
  }

  // Speech recognition hook
  const {
    transcript,
    isListening,
    isSupported: sttSupported,
    startListening,
    stopListening,
    resetTranscript,
    error: speechError,
  } = useSpeechRecognition(language)

  // Speech synthesis hook - passa a emo√ß√£o atual para ajustar a voz
  const { speak, cancel: cancelSpeech, isSpeaking } = useSpeechSynthesis(language, currentEmotion)

  // Stop listening when TTS is speaking to prevent transcribing the cat's voice
  // REMOVED: This was causing the microphone to turn off immediately in some cases
  /*
  useEffect(() => {
    if (isSpeaking && isListening) {
      console.log("[VisualNovelChat] TTS is speaking, stopping speech recognition to avoid transcribing cat's voice");
      stopListening();
    }
  }, [isSpeaking, isListening, stopListening])
  */

  // Cancel speech when switching to voice mode
  // REMOVED: Potential conflict
  /*
  useEffect(() => {
    if (inputMode === "text" && isListening) {
      stopListening();
    } else if (inputMode === "voice") {
      cancelSpeech();
    }
  }, [inputMode, isListening, stopListening, cancelSpeech])
  */

  // N√ÉO reiniciar automaticamente o reconhecimento - isso causa loops
  // O usu√°rio deve clicar no microfone para iniciar/parar manualmente
  // Removido o useEffect que reiniciava automaticamente para evitar loops

  // Sincronizar transcript com input em tempo real enquanto est√° ouvindo
  useEffect(() => {
    if (isListening && transcript) {
      // Atualizar o input com o transcript em tempo real
      setInput(transcript);
      // Tamb√©m atualizar o ref para garantir sincroniza√ß√£o
      if (inputRef.current) {
        inputRef.current.value = transcript;
      }
    }
  }, [transcript, isListening]);

  // Auto-speak assistant messages - APENAS UMA VEZ por mensagem
  // IMPORTANTE: N√£o falar se o usu√°rio est√° ouvindo (tentando falar)
  // IMPORTANTE: N√£o falar quando apenas muda o modo, apenas quando nova mensagem √© adicionada
  const previousMessagesLengthRef = useRef(0);
  useEffect(() => {
    // S√≥ processar se realmente h√° uma nova mensagem (length aumentou)
    if (messages.length > previousMessagesLengthRef.current && messages.length > 0 && inputMode === "voice") {
      const lastMessage = messages[messages.length - 1]
      
      // S√≥ falar se:
      // 1. √â uma mensagem do assistente
      // 2. N√£o est√° carregando
      // 3. Usu√°rio n√£o est√° ouvindo (e n√£o est√° tentando ouvir - dar mais tempo)
      // 4. √â uma NOVA mensagem (n√£o foi falada antes)
      if (
        lastMessage.role === "assistant" && 
        !loading && 
        !isListening &&
        lastMessage.id !== lastSpokenMessageIdRef.current
      ) {
        // Marcar que esta mensagem j√° foi falada
        lastSpokenMessageIdRef.current = lastMessage.id;
        console.log("[VisualNovelChat] Auto-speaking NEW assistant message (user not listening)");
        cancelSpeech()
        // Delay maior para garantir que o reconhecimento n√£o est√° sendo iniciado
        setTimeout(() => {
          // Verificar novamente se n√£o est√° ouvindo antes de falar
          if (!isListening) {
            speak(lastMessage.content, currentEmotion)
          } else {
            console.log("[VisualNovelChat] User started listening, skipping auto-speak");
          }
        }, 1000) // Aumentar delay para dar mais tempo ao usu√°rio
      } else if (isListening) {
        console.log("[VisualNovelChat] Skipping auto-speak: user is listening (trying to speak)");
      } else if (lastMessage.id === lastSpokenMessageIdRef.current) {
        console.log("[VisualNovelChat] Skipping auto-speak: message already spoken");
      }
    }
    
    // Atualizar o comprimento anterior
    previousMessagesLengthRef.current = messages.length;
  }, [messages, inputMode, loading, speak, cancelSpeech, isListening, stopListening, currentEmotion])

  // Auto-scroll para a √∫ltima mensagem
  useEffect(() => {
    if (messagesEndRef.current) {
      messagesEndRef.current.scrollIntoView({ behavior: "smooth", block: "nearest" })
    }
  }, [messages, loading])

  // Desabilitar scroll no body quando chat est√° aberto
  useEffect(() => {
    if (isOpen) {
      // Guardar o valor original do overflow
      const originalOverflow = document.body.style.overflow
      const originalPaddingRight = document.body.style.paddingRight
      
      // Desabilitar scroll
      document.body.style.overflow = 'hidden'
      
      return () => {
        // Restaurar scroll quando chat fecha
        document.body.style.overflow = originalOverflow
        document.body.style.paddingRight = originalPaddingRight
      }
    } else {
      // Stop listening when chat closes
      if (isListening) {
        stopListening();
      }
    }
  }, [isOpen, isListening, stopListening])

  // Focus input when chat opens
  useEffect(() => {
    if (isOpen && inputRef.current) {
      setTimeout(() => inputRef.current?.focus(), 100)
    }
  }, [isOpen])

  // Add welcome message when chat opens
  useEffect(() => {
    if (isOpen && messages.length === 0) {
      const welcomeMessages: Record<string, string> = {
        pt: "Ol√°! Sou o Miao, o gato verde mais rebelde da blockchain! üê±‚ú® O que queres saber?",
        en: "Hello! I'm Miao, the most rebellious green cat on the blockchain! üê±‚ú® What would you like to know?",
        es: "¬°Hola! Soy Miao, el gato verde m√°s rebelde de la blockchain! üê±‚ú® ¬øQu√© quieres saber?",
        fr: "Salut! Je suis Miao, le chat vert le plus rebelle de la blockchain! üê±‚ú® Que veux-tu savoir?",
        de: "Hallo! Ich bin Miao, die rebellischste gr√ºne Katze der Blockchain! üê±‚ú® Was m√∂chtest du wissen?",
        zh: "‰Ω†Â•ΩÔºÅÊàëÊòØMiaoÔºåÂå∫ÂùóÈìæ‰∏äÊúÄÂèõÈÄÜÁöÑÁªøÁå´ÔºÅüê±‚ú® ‰Ω†ÊÉ≥Áü•ÈÅì‰ªÄ‰πàÔºü",
        ar: "ŸÖÿ±ÿ≠ÿ®ÿßŸã! ÿ£ŸÜÿß ŸÖŸäÿßŸàÿå ÿßŸÑŸÇÿ∑ÿ© ÿßŸÑÿÆÿ∂ÿ±ÿßÿ° ÿßŸÑÿ£ŸÉÿ´ÿ± ÿ™ŸÖÿ±ÿØÿßŸã ŸÅŸä ÿßŸÑÿ®ŸÑŸàŸÉ ÿ™ÿ¥ŸäŸÜ! üê±‚ú® ŸÖÿßÿ∞ÿß ÿ™ÿ±ŸäÿØ ÿ£ŸÜ ÿ™ÿπÿ±ŸÅÿü",
      }
      
      const welcomeContent = welcomeMessages[language] || welcomeMessages["en"]
      const welcomeMessage: Message = {
        id: Date.now().toString(),
        role: "assistant",
        content: welcomeContent,
        timestamp: Date.now(),
      }
      setMessages([welcomeMessage])
      // Emo√ß√£o inicial para a mensagem de boas-vindas
      setCurrentEmotion("excited")
      // Falar a mensagem de boas-vindas na voz do idioma correto
      // Delay pequeno para garantir que a voz est√° carregada
      setTimeout(() => {
        speak(welcomeContent, "excited")
      }, 500)
    }
  }, [isOpen, messages.length, language, speak])

  // O v√≠deo de fundo √© gerenciado pelo Hero component - n√£o precisa fazer nada aqui

  const handleToggleVoice = () => {
    // Se j√° est√° ouvindo, parar
    if (isListening) {
      console.log("[VisualNovelChat] üõë Stopping voice input (toggle)");
      handleStopVoice();
      return;
    }
    
    // Don't start if TTS is speaking
    if (isSpeaking) {
      console.log("[VisualNovelChat] ‚ö†Ô∏è Cannot start voice input: TTS is speaking");
      return;
    }
    
    console.log("[VisualNovelChat] üé§ Starting voice input...");
    resetTranscript();
    setInput("");
    cancelSpeech();
    
    // Start listening immediately
    startListening();
    console.log("[VisualNovelChat] ‚úÖ Speech recognition started");
  }

  const handleStopVoice = () => {
    console.log("[VisualNovelChat] üõë Stopping voice input");
    stopListening();
    
    // Aguardar um pouco para garantir que o transcript final foi processado
    setTimeout(() => {
      // Capturar o transcript final e limpar espa√ßos extras
      const finalTranscript = transcript.trim();
      if (finalTranscript) {
        setInput(finalTranscript);
        // Tamb√©m atualizar o ref
        if (inputRef.current) {
          inputRef.current.value = finalTranscript;
        }
        console.log("[VisualNovelChat] ‚úÖ Final transcript captured:", finalTranscript);
      } else {
        console.log("[VisualNovelChat] ‚ö†Ô∏è No transcript to capture");
      }
    }, 300); // Pequeno delay para garantir processamento final
  }

  const handleCancelVoice = () => {
    console.log("[VisualNovelChat] üö´ Cancelling voice input");
    stopListening()
    resetTranscript()
    setInput("")
    // Focus on input after cancelling
    setTimeout(() => {
      if (inputRef.current) {
        inputRef.current.focus();
      }
    }, 100);
  }

  const handleSend = async () => {
    // Obter o texto do input de m√∫ltiplas fontes para garantir que capturamos o valor correto
    const inputValue = inputRef.current?.value.trim() || input.trim();
    console.log("[VisualNovelChat] üöÄ handleSend called");
    console.log("[VisualNovelChat] üìã Input state:", input);
    console.log("[VisualNovelChat] üìã Input ref value:", inputRef.current?.value);
    console.log("[VisualNovelChat] üìã Final message text:", inputValue);
    
    if (!inputValue || loading) {
      console.log("[VisualNovelChat] ‚ö†Ô∏è Cannot send: empty input or loading");
      return;
    }

    // Stop listening if active
    if (isListening) {
      console.log("[VisualNovelChat] üõë Stopping listening before send");
      stopListening();
      // Aguardar um pouco para garantir que o transcript final foi processado
      await new Promise(resolve => setTimeout(resolve, 500));
      // Atualizar inputValue com o valor mais recente
      const updatedText = inputRef.current?.value.trim() || input.trim();
      if (updatedText && updatedText !== inputValue) {
        console.log("[VisualNovelChat] üìù Updated message text from input ref:", updatedText);
      }
    }

    const finalMessageText = inputRef.current?.value.trim() || input.trim();
    console.log("[VisualNovelChat] üì§ Sending message to MIAO:", finalMessageText);
    
    if (!finalMessageText) {
      console.error("[VisualNovelChat] ‚ùå ERROR: Final message text is empty!");
      return;
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      role: "user",
      content: finalMessageText,
      timestamp: Date.now(),
    }

    setMessages((prev) => [...prev, userMessage])
    setInput("")
    resetTranscript()
    setLoading(true)
    setQueueProgress(null)

    try {
      // Usar API com streaming para receber atualiza√ß√µes de progresso
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 1800000) // 30 minutos timeout

      // Preparar hist√≥rico de conversa (√∫ltimas 10 mensagens para contexto)
      const conversationHistory = messages
        .slice(-10) // √öltimas 10 mensagens
        .map(msg => ({
          role: msg.role === "user" ? "user" : "assistant",
          content: msg.content,
        }))
      
      // Adicionar a nova mensagem do usu√°rio
      const conversationMessages = [
        ...conversationHistory,
        { role: "user" as const, content: userMessage.content },
      ]

      const response = await fetch("/api/generate-text-stream", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          messages: conversationMessages, // Enviar hist√≥rico completo
          maxLength: 100, // Modelo econ√¥mico - respostas curtas (~75 palavras)
          temperature: 0.8, // Mais alto para respostas mais naturais
          topP: 0.9,
          model: "meta-llama/Llama-3.2-1B-Instruct", // Modelo Hugging Face (chat completions)
          language: language,
        }),
        signal: controller.signal,
      })

      clearTimeout(timeoutId)

      if (!response.ok) {
        let errorMessage = "Failed to generate text"
        try {
          const errorData = await response.json()
          errorMessage = errorData.error || errorMessage
        } catch {
          errorMessage = `HTTP ${response.status}: ${response.statusText}`
        }
        throw new Error(errorMessage)
      }

      // Ler stream de eventos
      const reader = response.body?.getReader()
      const decoder = new TextDecoder()
      let buffer = ""

      if (!reader) {
        throw new Error("No response stream available")
      }

      let generatedText: string | null = null
      let streamError: string | null = null
      let hasReceivedData = false

      try {
        while (true) {
          const { done, value } = await reader.read()

          if (done) {
            console.log("Stream ended. Generated text:", generatedText ? "received" : "not received")
            break
          }

          hasReceivedData = true
          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split("\n\n")
          buffer = lines.pop() || ""

          for (const line of lines) {
            if (line.trim() && line.startsWith("data: ")) {
              try {
                const jsonStr = line.slice(6).trim()
                if (!jsonStr) continue
                
                const data = JSON.parse(jsonStr)
                console.log("Received SSE data:", data.type, data)

                if (data.type === "progress") {
                  // Atualizar progresso da fila
                  const queuePosition = data.queuePosition || 0
                  setQueueProgress({
                    queuePosition: queuePosition,
                    progress: data.progress || 0,
                  })
                  
                  // Se queuePosition for -1, significa que n√£o h√° workers dispon√≠veis
                  if (queuePosition === -1) {
                    console.log("No workers available, request queued and waiting...")
                  }
                } else if (data.type === "complete") {
                  console.log("Received complete message, text length:", data.text?.length || 0)
                  if (data.text && typeof data.text === "string" && data.text.trim()) {
                    generatedText = data.text.trim()
                    console.log("Generated text set:", generatedText.substring(0, 50) + "...")
                  } else {
                    console.warn("Complete message received but text is empty or invalid:", data)
                    streamError = "Generated text is empty"
                  }
                } else if (data.type === "error") {
                  console.error("Error received from stream:", data.error)
                  streamError = data.error || "Text generation failed"
                }
              } catch (parseError) {
                console.warn("Failed to parse SSE data:", parseError, "Line:", line)
              }
            } else if (line.trim() && !line.startsWith("data: ")) {
              // Log non-SSE lines for debugging
              console.warn("Unexpected line format:", line.substring(0, 100))
            }
          }
        }

        // Se n√£o recebemos nenhum dado, pode ser um problema de conex√£o
        if (!hasReceivedData) {
          console.error("No data received from stream")
          streamError = "No data received from server"
        }
      } catch (streamReadError: any) {
        console.error("Error reading stream:", streamReadError)
        streamError = streamReadError?.message || "Error reading response stream"
      } finally {
        try {
          reader.releaseLock()
        } catch (releaseError) {
          console.warn("Error releasing reader lock:", releaseError)
        }
      }

      // Verificar se houve erro no stream
      if (streamError) {
        // Melhorar mensagens de erro espec√≠ficas
        let errorMessage = streamError
        
        if (streamError.includes("Input payload validation failed") || 
            streamError.includes("validation failed")) {
          errorMessage = t("chat.invalidParams")
        } else if (streamError.includes("timeout") || streamError.includes("timed out")) {
          errorMessage = t("chat.timeout")
        } else if (streamError.includes("not found") || streamError.includes("404")) {
          errorMessage = t("chat.serviceUnavailable")
        }
        
        throw new Error(errorMessage)
      }

      // Verificar se recebemos texto
      if (!generatedText) {
        throw new Error(t("chat.noResponse"))
      }

      const assistantMessage: Message = {
        id: Date.now().toString(),
        role: "assistant",
        content: generatedText,
        timestamp: Date.now(),
      }

      // Detectar emo√ß√£o na resposta e atualizar
      const detectedEmotion = detectEmotion(generatedText)
      console.log("Detected emotion:", detectedEmotion, "from text:", generatedText.substring(0, 100))
      setCurrentEmotion(detectedEmotion)

      setMessages((prev) => [...prev, assistantMessage])
      
      // Auto-speak if in voice mode
      if (inputMode === "voice") {
        // Stop listening before speaking to avoid transcribing the cat's voice
        if (isListening) {
          stopListening();
        }
        cancelSpeech()
        setTimeout(() => {
          speak(assistantMessage.content, detectedEmotion)
        }, 500)
      }
    } catch (error: any) {
      console.error("Chat error:", error)
      
      // Check if all API keys failed - show friendly cat message
      if (error?.message?.includes("MIAO_ALL_KEYS_FAILED") || 
          error?.message?.includes("ALL_KEYS_FAILED")) {
        const tiredMessage: Message = {
          id: Date.now().toString(),
          role: "assistant",
          content: t("chat.tired"),
          timestamp: Date.now(),
        }
        
        // Detectar emo√ß√£o "sleepy" para a mensagem de cansado
        setCurrentEmotion("sleepy")
        setMessages((prev) => [...prev, tiredMessage])
        
        // Auto-speak if in voice mode
        if (inputMode === "voice") {
          if (isListening) {
            stopListening();
          }
          cancelSpeech()
          setTimeout(() => {
            speak(tiredMessage.content, "sleepy")
          }, 500)
        }
        return
      }
      
      // Don't show "Authentication failed" errors to user
      if (error?.message?.toLowerCase().includes("authentication failed") || 
          error?.message?.toLowerCase().includes("authentication required")) {
        // Silently retry or show generic error
        const genericMessage: Message = {
          id: Date.now().toString(),
          role: "assistant",
          content: t("chat.genericError"),
          timestamp: Date.now(),
        }
        setMessages((prev) => [...prev, genericMessage])
        return
      }
      
      // Mensagem de erro mais espec√≠fica baseada no idioma
      let errorMessageText = t("chat.genericError")
      
      if (error?.message) {
        // Se for um erro de timeout ou conex√£o, usar mensagem espec√≠fica
        if (error.name === "AbortError" || error.message.includes("timeout")) {
          errorMessageText = t("chat.timeout")
        } else if (error.message.includes("network") || error.message.includes("fetch")) {
          errorMessageText = t("chat.serviceUnavailable")
        } else {
          // Usar a mensagem de erro espec√≠fica se dispon√≠vel (mas n√£o mostrar "Authentication failed")
          if (!error.message.toLowerCase().includes("authentication")) {
            errorMessageText = error.message
          }
        }
      }
      
      const errorMessage: Message = {
        id: Date.now().toString(),
        role: "assistant",
        content: errorMessageText,
        timestamp: Date.now(),
      }
      setMessages((prev) => [...prev, errorMessage])
    } finally {
      setLoading(false)
      setQueueProgress(null)
    }
  }

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault()
      handleSend()
    }
  }

  // Fun√ß√£o para reproduzir/pausar √°udio de uma mensagem espec√≠fica
  const handlePlayPauseMessage = (message: Message) => {
    if (playingMessageId === message.id && isSpeaking) {
      // Se est√° reproduzindo esta mensagem, pausar
      cancelSpeech()
      setPlayingMessageId(null)
    } else {
      // Se n√£o est√° reproduzindo ou √© outra mensagem, reproduzir
      cancelSpeech()
      setPlayingMessageId(message.id)
      
      // Detectar emo√ß√£o da mensagem
      const detectedEmotion = detectEmotion(message.content)
      setCurrentEmotion(detectedEmotion)
      
      // Reproduzir ap√≥s pequeno delay
      setTimeout(() => {
        speak(message.content, detectedEmotion)
      }, 100)
    }
  }

  // Atualizar playingMessageId quando a fala terminar
  useEffect(() => {
    if (!isSpeaking && playingMessageId) {
      setPlayingMessageId(null)
    }
  }, [isSpeaking, playingMessageId])

  if (!isOpen) return null

  return (
    <div className="fixed inset-0 z-50 flex flex-col bg-transparent overflow-hidden">
      {/* O v√≠deo de fundo j√° est√° instanciado no Hero - apenas deixamos o background transparente para ele aparecer */}

      {/* Layout vertical em todas as resolu√ß√µes: Chat ‚Üí Gato ‚Üí Input */}
      <div className="flex flex-col h-full w-full flex-1 min-h-0 relative z-10">
        {/* Chat Area - No topo - Sem background para transi√ß√£o suave */}
        <div className="flex-1 flex flex-col min-w-0 min-h-0 relative overflow-hidden bg-transparent">
          {/* √Årea de mensagens - Visual Novel Style com bal√µes de conversa */}
          <div className="flex-1 overflow-y-auto overflow-x-hidden p-3 sm:p-4 md:p-4 lg:p-6 space-y-3 sm:space-y-4 pt-14 sm:pt-20 md:pt-6 pb-8 relative">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.role === "user" ? "justify-end" : "justify-start"} w-full`}
          >
            <div
              className={
                `max-w-[90%] sm:max-w-[80%] md:max-w-[75%] lg:max-w-[70%] rounded-xl sm:rounded-2xl p-3 sm:p-4 shadow-xl transition-all duration-200 ${
                  message.role === "user"
                    ? "bg-[var(--brand)] text-white shadow-[var(--brand)]/30"
                    : "bg-[var(--bg-secondary)]/95 backdrop-blur-md text-[var(--text-primary)] border-2 border-[var(--border-color)]/80 shadow-black/20"
                }`
              }
            >
              <div className="flex items-start gap-2">
                <p className="text-xs sm:text-sm md:text-base whitespace-pre-wrap break-words leading-relaxed flex-1">
                  {message.content}
                </p>
                {/* Bot√£o de play/pause apenas para mensagens do assistente */}
                {message.role === "assistant" && (
                  <button
                    onClick={() => handlePlayPauseMessage(message)}
                    className="flex-shrink-0 w-6 h-6 sm:w-7 sm:h-7 flex items-center justify-center rounded-full bg-[var(--bg-tertiary)] hover:bg-[var(--bg-primary)] border border-[var(--border-color)] transition-all hover:scale-110 active:scale-95"
                    title={playingMessageId === message.id && isSpeaking ? t("chat.pause") : t("chat.play")}
                  >
                    {playingMessageId === message.id && isSpeaking ? (
                      <Pause size={12} className="sm:w-3.5 sm:h-3.5 text-[var(--text-primary)]" />
                    ) : (
                      <Play size={12} className="sm:w-3.5 sm:h-3.5 text-[var(--text-primary)]" />
                    )}
                  </button>
                )}
              </div>
            </div>
          </div>
        ))}

        {loading && (
          <div className="flex justify-start">
            <div className="bg-[var(--bg-secondary)]/95 backdrop-blur-md border-2 border-[var(--border-color)]/80 rounded-xl sm:rounded-2xl p-3 sm:p-4 flex items-center gap-2 shadow-xl shadow-black/20">
              <Loader2 className="animate-spin" size={16} />
              <span className="text-xs sm:text-sm text-[var(--text-primary)]">
                {queueProgress && queueProgress.queuePosition === -1
                  ? t("chat.waitingWorkers")
                  : queueProgress && queueProgress.queuePosition > 0
                  ? `${t("chat.inQueue")}: ${queueProgress.queuePosition}`
                  : t("chat.thinking")}
              </span>
            </div>
          </div>
        )}

            <div ref={messagesEndRef} />
          </div>
        </div>

        {/* Caixa do Gato - No meio, entre chat e input - Sem divis√≥rias vis√≠veis, por tr√°s do input */}
        <div className="flex flex-col w-full bg-transparent flex-shrink-0 relative" style={{ zIndex: 10, margin: 0, padding: 0 }}>
          {/* √Årea do gato - Visual Novel: centralizado, n√£o trespassa o topo, sem paddings/margins */}
          <div 
            className="flex items-center justify-center relative"
            style={{ 
              minHeight: "350px", 
              maxHeight: "500px",
              height: "400px",
              margin: 0,
              padding: 0,
              overflow: 'hidden', // N√£o trespassa o topo
              position: 'relative',
            }}
          >
            <div className="w-full h-full flex items-center justify-center relative" style={{ overflow: 'hidden', margin: 0, padding: 0 }}>
              <TamagotchiCat isChatMode={true} emotion={currentEmotion} />
            </div>
            
            {/* Label Miao - Sobreposta ao gradient bottom */}
            <div 
              className="absolute bottom-0 left-0 right-0 flex-shrink-0 pointer-events-none"
              style={{ 
                zIndex: 20,
                paddingBottom: '10px',
              }}
            >
              <h3 className="text-xs sm:text-sm font-bold text-[var(--text-primary)] text-center">
                {t("chat.miao")}
              </h3>
            </div>
          </div>
        </div>
        
        {/* Footer - Input area no final - Visual Novel Style - Por cima do gato */}
        <div className="flex-shrink-0 p-2 sm:p-4 bg-[var(--bg-secondary)]/95 backdrop-blur-md border-t-2 border-[var(--border-color)] shadow-[0_-4px_20px_rgba(0,0,0,0.15)] relative" style={{ zIndex: 30 }}>
            <div className="w-full max-w-full">
              {/* Mode toggle - ocultar em mobile muito pequeno */}
              {sttSupported && (
                <div className="flex flex-col gap-2 mb-2">
                  <div className="flex items-center gap-2">
                    <button
                      onClick={() => {
                        const newMode = inputMode === "text" ? "voice" : "text";
                        console.log(`[VisualNovelChat] üîÑ Changing input mode from ${inputMode} to ${newMode}`);
                        setInputMode(newMode);
                        // Se mudou para voice, cancelar qualquer fala em andamento
                        if (newMode === "voice") {
                          cancelSpeech();
                          console.log("[VisualNovelChat] üîá Cancelled any ongoing speech when switching to voice mode");
                        }
                      }}
                      className="text-xs px-2 sm:px-3 py-1 rounded-lg bg-[var(--bg-tertiary)] border border-[var(--border-color)] text-[var(--text-secondary)] hover:bg-[var(--bg-primary)] transition-all flex items-center gap-1"
                    >
                      {inputMode === "text" ? (
                        <>
                          <Mic size={12} className="sm:w-3.5 sm:h-3.5" />
                          <span className="hidden sm:inline">{t("chat.voiceMode")}</span>
                        </>
                      ) : (
                        <>
                          <Keyboard size={12} className="sm:w-3.5 sm:h-3.5" />
                          <span className="hidden sm:inline">{t("chat.textMode")}</span>
                        </>
                      )}
                    </button>
                  </div>
                  {/* Mostrar erro de microfone se houver, exceto network error que pode ser transiente */}
                  {speechError && speechError !== "network" && !speechError.includes("network") && (
                    <div className="text-xs text-red-400 bg-red-500/10 border border-red-500/20 rounded-lg px-2 py-1">
                      {speechError}
                    </div>
                  )}
                </div>
              )}
              
              <div className="flex gap-2">
                <div className="flex-1 relative">
                  <input
                    ref={inputRef}
                    type="text"
                    value={input}
                    onChange={(e) => {
                      // Allow manual editing even in voice mode (user can correct transcription)
                      const newValue = e.target.value;
                      setInput(newValue);
                      console.log("[VisualNovelChat] Input manually changed to:", newValue);
                    }}
                    onKeyPress={handleKeyPress}
                    placeholder={
                      inputMode === "voice"
                        ? (isListening ? t("chat.speaking") : (input.trim() ? t("chat.editOrSend") : t("chat.clickToSpeak")))
                        : t("chat.typeMessage")
                    }
                    disabled={loading}
                    readOnly={inputMode === "voice" && isListening}
                    className="w-full bg-[var(--bg-tertiary)] border-2 border-[var(--border-color)] rounded-xl sm:rounded-2xl px-3 sm:px-4 py-2 sm:py-3 text-sm sm:text-base text-[var(--text-primary)] placeholder:text-[var(--text-secondary)] focus:outline-none focus:border-[var(--brand)] disabled:opacity-50"
                  />
                  {/* Indicador visual quando h√° texto transcrito */}
                  {inputMode === "voice" && !isListening && input.trim() && (
                    <div className="absolute -top-6 left-0 text-xs text-[var(--brand)] bg-[var(--bg-secondary)] px-2 py-1 rounded border border-[var(--brand)]/30">
                      {t("chat.transcribed")} ‚úì
                    </div>
                  )}
                </div>
                
                {sttSupported && inputMode === "voice" && (
                  <button
                    onClick={handleToggleVoice}
                    disabled={loading || isSpeaking}
                    className={`${
                      isListening 
                        ? "bg-red-500 hover:bg-red-600" 
                        : "bg-[var(--brand)] hover:brightness-110"
                    } text-white px-3 sm:px-4 py-2 sm:py-3 rounded-xl sm:rounded-2xl font-bold disabled:opacity-50 disabled:cursor-not-allowed transition-all flex items-center justify-center`}
                    title={
                      isSpeaking 
                        ? t("chat.waitCatFinish")
                        : isListening
                        ? t("chat.stopRecording")
                        : t("chat.startRecording")
                    }
                  >
                    <Mic 
                      size={18} 
                      className={`sm:w-5 sm:h-5 ${isListening ? 'animate-pulse' : ''}`}
                      style={isListening ? { 
                        filter: 'brightness(1.5)',
                        transform: 'scale(1.1)'
                      } : undefined}
                    />
                  </button>
                )}
                
                <button
                  onClick={handleSend}
                  disabled={loading || !input.trim()}
                  className="bg-[var(--brand)] text-white px-4 sm:px-6 py-2 sm:py-3 rounded-xl sm:rounded-2xl font-bold hover:brightness-110 disabled:opacity-50 disabled:cursor-not-allowed transition-all flex items-center justify-center"
                >
                  {loading ? (
                    <Loader2 className="animate-spin sm:w-5 sm:h-5" size={18} />
                  ) : (
                    <Send className="sm:w-5 sm:h-5" size={18} />
                  )}
                </button>
              </div>
            </div>
          </div>
      </div>

      {/* Close button - floating top right */}
      <button
        onClick={onClose}
        className="fixed top-2 right-2 sm:top-4 sm:right-4 z-[55] w-8 h-8 sm:w-10 sm:h-10 flex items-center justify-center rounded-lg sm:rounded-xl bg-black/60 backdrop-blur-sm border-2 border-white/30 hover:bg-red-500/70 hover:border-red-500 transition-all shadow-lg"
      >
        <X size={16} className="sm:w-5 sm:h-5 text-white" />
      </button>

      {/* Voice Indicator */}
      {sttSupported && (
        <VoiceIndicator
          isListening={isListening}
          transcript={transcript}
          onStop={handleStopVoice}
          onCancel={handleCancelVoice}
        />
      )}
    </div>
  )
}
